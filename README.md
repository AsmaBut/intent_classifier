

```
# ğŸš€ FastAPI Intent Classifier

This project is a **FastAPI-based Intent Classification API** that classifies user queries into predefined intents (e.g., sending email, scheduling calendar events, or performing web searches).  
It uses **Machine Learning models** (TF-IDF + Logistic Regression / SVM) trained on both real and synthetic datasets.  
The project is containerized using **Docker** for easy deployment.

---

## ğŸ“‚ Project Structure

```

intent_classifier/
â”‚â”€â”€ main.py                     # FastAPI app entry point
â”‚â”€â”€ create_dataset.py           # Script to generate synthetic noisy dataset
â”‚â”€â”€ requirements.txt            # Python dependencies
â”‚â”€â”€ Dockerfile                  # Docker setup for deployment
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ full_dataset.csv        # Complete dataset
â”‚   â”œâ”€â”€ train_dataset.csv       # Training split
â”‚   â”œâ”€â”€ validation_dataset.csv  # Validation split
â”‚   â””â”€â”€ test_dataset.csv        # Testing split
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ intent_model.pkl        # Trained classification model
â”‚   â”œâ”€â”€ tfidf_vectorizer.pkl    # TF-IDF vectorizer
â”‚   â””â”€â”€ label_encoder.pkl       # Encodes class labels
â”‚
â””â”€â”€ tests/
â””â”€â”€ test_main.py            # Unit tests for API
â””â”€â”€ collab_notebook.py

````

---

## âš¡ Features

- Train ML model on data.  
- REST API built with **FastAPI**.  
- Predict intent from user queries.  
- Includes **unit tests** with `pytest`.  
- Ready for **Docker deployment**.  

---

## ğŸ”§ Installation & Setup

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/AsmaBut/intent_classifier.git
cd intent_classifier
````

### 2ï¸âƒ£ Create & activate virtual environment

```bash
python -m venv venv
venv\Scripts\activate   # On Windows
source venv/bin/activate  # On Linux/Mac
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Running the API Locally

Start the FastAPI server:

```bash
uvicorn main:app --reload
```

Open your browser or use Postman at:

```
http://127.0.0.1:8000/docs
```

Here you can test the API endpoints with Swagger UI.


## ğŸ“Œ API Endpoints

### 1. Health Check

**GET** `/api/health`

* **Description**: Verify that the API is running.
* **Response**:

```json
{
  "status": "ok"
}
```

---

### 2. Model Info

**GET** `/api/model/info`

* **Description**: Get details about the trained model.
* **Response**:

```json
{
  "model": "intent_classifier",
  "version": "1.0",
  "labels": ["email_send", "calendar_schedule", "web_search"]
}
```

---

### 3. Classify Single

**POST** `/api/classify`

* **Description**: Classify intent for a single text input.
* **Request Body**:

```json
{
  "text": "schedule a meeting tomorrow at 5 pm"
}
```

* **Response**:

```json
{
  "intent": "calendar_schedule",
  "confidence": 0.87
}
```

---

### 4. Classify Batch

**POST** `/api/classify/batch`

* **Description**: Classify intents for multiple texts in one request.
* **Request Body**:

```json
{
  "texts": [
    "send email to HR",
    "search for AI conferences",
    "set up a meeting on Friday"
  ]
}
```

* **Response**:

```json
[
  {"intent": "email_send", "confidence": 0.91},
  {"intent": "web_search", "confidence": 0.85},
  {"intent": "calendar_schedule", "confidence": 0.89}
]
```

---

## ğŸ³ Running with Docker

### 1ï¸âƒ£ Build Docker image

```bash
docker build -t intent-classifier .
```

### 2ï¸âƒ£ Run container

```bash
docker run -p 8000:8000 intent-classifier
```

Now the API is available at:

```
http://127.0.0.1:8000/docs
```

---

## ğŸ§ª Running Tests

```bash
pytest tests/
```

---

## ğŸ“Š Dataset

* Synthetic dataset generated with `create_dataset.py`.
* Includes **noise injection** to ensure model accuracy remains below ~80%.
* Data splits:

  * Train
  * Validation
  * Test

---

## ğŸš€ Deployment

This project is ready for deployment to:

* **Railway.app**
* **Render**
* **DockerHub + VPS**

---



